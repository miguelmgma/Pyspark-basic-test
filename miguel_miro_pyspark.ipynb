{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ0JmBw4uSPc"
      },
      "source": [
        "# Examen PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ1VYgmsuSPh"
      },
      "source": [
        "Instrucciones: Lea cuidadosamente las preguntas, escriba el código correspondiente y ejecútelo para mostrar sus resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw8pf_LruSPi"
      },
      "source": [
        "#### Importante: Todos los ejercicios deberán realizarse con funciones de NumPy, Pandas o PySpark (no podrán crearse vistas temporales para realizarse en SQL, salvo que se indique lo contrario)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTO7IB5KuSPj"
      },
      "source": [
        "## Bloque 1: Spark Core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBke8XxguSPk"
      },
      "source": [
        "1.1 Utilizando NumPy, construya un arreglo con 50 elementos aleatorios distribuidos de forma normal con media 50 y desviación estándar 10. Imprima el arreglo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs9hP17xuY6c",
        "outputId": "afed214d-4714-43f4-fd28-757cafa92fab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([44.0251056 , 41.80131532, 65.59643072, 54.46644056, 59.07774891,\n",
              "       62.16234455, 58.87508386, 57.60313253, 51.20836849, 58.58433125,\n",
              "       38.33169469, 43.7330064 , 37.91027826, 46.47981224, 60.59702034,\n",
              "       42.32264255, 45.10334199, 29.74525001, 60.57731582, 47.71479966,\n",
              "       41.94094009, 27.85930919, 27.66496622, 60.57031692, 60.7169846 ,\n",
              "       57.12572408, 30.3324811 , 52.96444014, 46.29664653, 42.6286651 ,\n",
              "       62.26153014, 61.16674644, 38.23954255, 45.17568383, 44.6544177 ,\n",
              "       39.8588725 , 47.7528372 , 57.88631696, 59.08660794, 46.25934663,\n",
              "       53.02125492, 47.52741738, 41.41978578, 45.17683168, 37.75888656,\n",
              "       57.59616115, 19.98408932, 24.34224681, 43.61710942, 57.3577041 ])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "mean = 50\n",
        "std = 10\n",
        "\n",
        "dist = np.random.normal(mean, std, 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYWEtXDuuSPk"
      },
      "source": [
        "[link text](https://)1.2. Construya el objeto de Spark (Core) que le permita trabajar con objetos RDD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CGRp7Mz6u2Ax"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "sc = SparkContext(appName=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm2vWXwzuSPk"
      },
      "source": [
        "1.3. Convierta el arreglo de NumPy a un RDD con 2 particiones. Muestre los primeros 5 elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFfT-bR4vUcR",
        "outputId": "77a53e3e-4b6a-4f0a-af96-29b6b4bcf4da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[44.02510560246526, 41.80131532451206, 65.5964307230606, 54.466440563568625, 59.07774890739168]\n"
          ]
        }
      ],
      "source": [
        "rdd = sc.parallelize(dist, numSlices=2)\n",
        "print(rdd.take(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38zGAHdyuSPl"
      },
      "source": [
        "1.4. Suponiendo que los datos de la lista miden grados Fahrenheit, aplique una función lambda al RDD que convierta las mediciones a grados Centígrados. Muestre los primeros 5 elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA0YsrAevvwZ",
        "outputId": "19f108db-36e6-4b58-ad30-0669823f674c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[6.680614223591811,\n",
              " 5.445175180284478,\n",
              " 18.664683735033673,\n",
              " 12.481355868649237,\n",
              " 15.043193837439823]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# cels = (farenheit - 32) * 5/9\n",
        "\n",
        "rdd_cels = rdd.map(lambda f: (f - 32) * 5/9)\n",
        "\n",
        "rdd_cels.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaZ2NhFCuSPl"
      },
      "source": [
        "C = (F - 32) * 5 / 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx7WQowYuSPm"
      },
      "source": [
        "1.5. Utilice una función Lambda para mostrar únicamente las temperaturas mayores a 15 grados Centigrados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmkvdVpUwSxb",
        "outputId": "14aa047e-8be4-4f33-d15d-fcae9a02cd73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[18.664683735033673,\n",
              " 15.043193837439823,\n",
              " 16.75685808223599,\n",
              " 15.887233521055773,\n",
              " 15.876286567288266,\n",
              " 15.872398290455514,\n",
              " 15.953880331280383,\n",
              " 16.811961188562798,\n",
              " 16.20374802046699,\n",
              " 15.048115521196015]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_filt = rdd_cels.filter(lambda t: t> 15)\n",
        "rdd_filt.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ98lOgbuSPm"
      },
      "source": [
        "1.6. Calcule la temperatura media en grados Centígrados.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPrPlB_aw3fD",
        "outputId": "69a847c5-7f19-4cd0-dc02-cb2e23e86de4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.7128814081594"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_cels.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA8zdvytxbwk",
        "outputId": "2bf108fa-e273-420b-cde7-14b66c047b8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.712881408159403"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju79QghxuSPn"
      },
      "source": [
        "1.7. Obtenga las 3 temperaturas más altas en grados Centígrados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABhwOkE4xUgA",
        "outputId": "e15efbb1-6e84-40b9-df4b-06f0cd37776e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[18.664683735033673, 16.811961188562798, 16.75685808223599]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_cels.top(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj_6hxpcuSPn"
      },
      "source": [
        "## Bloque 2: Spark SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFI_edjguSPn"
      },
      "source": [
        "2.1. Utilizando Numpy, construya un arreglo con 50 números enteros entre 1 y 3 (1 y 3 incluidos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGoucVtMyIH2",
        "outputId": "8943bb7b-549c-4aa4-d271-7c047be4c2c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 2, 1, 1, 2, 2, 2, 3, 2, 2, 1, 3, 2, 2, 1, 1, 1, 2, 1, 1, 2,\n",
              "       2, 3, 2, 1, 2, 3, 3, 3, 3, 2, 1, 2, 1, 3, 3, 2, 3, 2, 3, 2, 2, 2,\n",
              "       1, 3, 2, 3, 1, 1])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dist1 =  np.random.randint(1, 4, size=50)\n",
        "dist1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsTGhWCHuSPo"
      },
      "source": [
        "2.2. Construya un dataframe en Pandas utilizando los arreglos de 2.1 y 1.1. Asigne los nombres \"dia\" y \"temp\". Muestre los primeros 5 elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RHMzFwRQyYqQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'dia': dist1, 'temp': dist})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feSyePWvuSPo"
      },
      "source": [
        "2.3. Construya el objeto de Spark (SQL) que le permita trabajar con los dataframes de Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "F14B9cJwyuSc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"test2\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk4n_GLXuSPp"
      },
      "source": [
        "2.4. Convierta el dataframe de Pandas a un dataframe de Spark, definiendo explícitamente el esquema/estructura (utilice el tipo entero para el día y el tipo doble para la temperatura). Muestre los primeros 5 registros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9T5BXmH1zAUk"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"dia\", IntegerType(), True),\n",
        "    StructField(\"temp\", DoubleType(), True)\n",
        "])\n",
        "\n",
        "df_spark = spark.createDataFrame(df, schema=schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRdqamMfuSPp"
      },
      "source": [
        "2.5. Partiendo del dataframe en Spark, construya un dataframe con el promedio de temperatura agrupado por día. El dataframe deberá contener únicamente las columnas \"dia\" y \"temp_prom\" (con esos nombres). Muestre la tabla resultante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmLPZJY-zS9o",
        "outputId": "6f5d791b-a4e4-4a6f-cb21-3d5e1fdd42a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+------------------+\n",
            "|dia|         temp_prom|\n",
            "+---+------------------+\n",
            "|  1|45.918396756442476|\n",
            "|  3| 48.08830980166919|\n",
            "|  2| 48.57033929138635|\n",
            "+---+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "df_prom = df_spark.groupBy('dia').agg(F.avg('temp').alias('temp_prom'))\n",
        "\n",
        "df_prom.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5FRYvDZuSPp"
      },
      "source": [
        "2.6. Repita el ejercicio anterior registrando una vista temporal y ejecutando el código SQL correspondiente. Muestre la tabla resultante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmnqFtO-0BXm",
        "outputId": "f775d30b-d79e-4bca-9aa2-446d69d5f20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+------------------+\n",
            "|dia|         temp_prom|\n",
            "+---+------------------+\n",
            "|  1|45.918396756442476|\n",
            "|  3| 48.08830980166919|\n",
            "|  2| 48.57033929138635|\n",
            "+---+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark.createOrReplaceTempView(\"vw_df\")\n",
        "view = spark.sql(\"select dia,mean(temp) as temp_prom from vw_df group by dia\")\n",
        "view.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik2VFaeduSPq"
      },
      "source": [
        "2.7. Combine los valores del dataframe anterior con el original. El dataframe resultante no deberá contener columnas repetidas y tendrá que estar ordenado de forma ascendente por día y temperatura. Muestre los primeros 5 elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7KOsuDf0p30",
        "outputId": "eedf540c-2958-4beb-d68c-214709c49dca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+------------------+------------------+\n",
            "|dia|              temp|         temp_prom|\n",
            "+---+------------------+------------------+\n",
            "|  1|29.745250013573642|45.918396756442476|\n",
            "|  1| 37.75888656179124|45.918396756442476|\n",
            "|  1| 38.23954255079114|45.918396756442476|\n",
            "|  1| 41.94094008650316|45.918396756442476|\n",
            "|  1| 42.32264254973991|45.918396756442476|\n",
            "+---+------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_join = df_spark.join(view, 'dia','inner')\n",
        "df_join = df_join.orderBy(F.asc(\"dia\"), F.asc(\"temp\"))\n",
        "df_join.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOUIzElYuSPq"
      },
      "source": [
        "2.8. Añada una columna adicicional con la diferencia entre la temperatura y su media. Asigne el nombre \"resid\". Muestre los primeros 5 elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWQJHhyn2KGV",
        "outputId": "28120abb-4a5c-4c58-ae19-3751dc1c7ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+------------------+------------------+-------------------+\n",
            "|dia|              temp|         temp_prom|              resid|\n",
            "+---+------------------+------------------+-------------------+\n",
            "|  1|29.745250013573642|45.918396756442476|-16.173146742868834|\n",
            "|  1| 37.75888656179124|45.918396756442476| -8.159510194651233|\n",
            "|  1| 38.23954255079114|45.918396756442476| -7.678854205651334|\n",
            "|  1| 41.94094008650316|45.918396756442476| -3.977456669939315|\n",
            "|  1| 42.32264254973991|45.918396756442476|-3.5957542067025656|\n",
            "+---+------------------+------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_join2 = df_join.withColumn('resid', (F.col('temp') - F.col('temp_prom')))\n",
        "df_join2.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsmjLAapuSPr"
      },
      "source": [
        "2.9. Construya un dataframe con todos los registros que posean residuales negativos. Muestre los primeros 5 elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwE45ydN2k_K",
        "outputId": "e9bf0dad-bfd4-4ff8-de55-384621526a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+------------------+------------------+-------------------+\n",
            "|dia|              temp|         temp_prom|              resid|\n",
            "+---+------------------+------------------+-------------------+\n",
            "|  1|29.745250013573642|45.918396756442476|-16.173146742868834|\n",
            "|  1| 37.75888656179124|45.918396756442476| -8.159510194651233|\n",
            "|  1| 38.23954255079114|45.918396756442476| -7.678854205651334|\n",
            "|  1| 41.94094008650316|45.918396756442476| -3.977456669939315|\n",
            "|  1| 42.32264254973991|45.918396756442476|-3.5957542067025656|\n",
            "+---+------------------+------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_join3 = df_join2.filter(F.col('resid') < 0)\n",
        "df_join3.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y73tl1q3uSPr"
      },
      "source": [
        "2.10. Guarde el dataframe resultante en formato JSON. En caso de que el archivo ya exista, deberá sobreescribirse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "IRM0Bb4N4LVb"
      },
      "outputs": [],
      "source": [
        "df_join3.write.mode(\"overwrite\").json(\"df_resultante.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMiwqrmCuSPr"
      },
      "source": [
        "## Bloque 3: Spark MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXfXoY7ruSPs"
      },
      "source": [
        "#### En esta sección se evalúan los conocimientos de Spark MLlib. Si bien son necesarios los conociemientos en Machine Learning, el candidato no será evaluado por la calidad del modelo producido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttEiLjWNuSPs"
      },
      "source": [
        "3.1. Cargue los datos del archivo 'data.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "L50_kBdw4iCZ"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(\"data.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiVsE01quSPt"
      },
      "source": [
        "3.2. Realicé un análisis exploratorio preliminar de los datos (estadísticos básicos de las columnas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6U0IsrD5uw8",
        "outputId": "bd7ab72a-7015-472f-9a9a-7e3856f4605f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Names: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- Total_Purchase: double (nullable = true)\n",
            " |-- Account_Manager: integer (nullable = true)\n",
            " |-- Years: double (nullable = true)\n",
            " |-- Num_Sites: double (nullable = true)\n",
            " |-- Onboard_date: timestamp (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Company: string (nullable = true)\n",
            " |-- Churn: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyD0mLTM4toa",
        "outputId": "f2b0798b-bd44-4d95-e128-7db1f8b1cbe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
            "|summary|        Names|              Age|   Total_Purchase|   Account_Manager|            Years|         Num_Sites|            Location|             Company|              Churn|\n",
            "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
            "|  count|          900|              900|              900|               900|              900|               900|                 900|                 900|                900|\n",
            "|   mean|         NULL|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|                NULL|                NULL|0.16666666666666666|\n",
            "| stddev|         NULL|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969|                NULL|                NULL| 0.3728852122772358|\n",
            "|    min|   Aaron King|             22.0|            100.0|                 0|              1.0|               3.0|00103 Jeffrey Cre...|     Abbott-Thompson|                  0|\n",
            "|    max|Zachary Walsh|             65.0|         18026.01|                 1|             9.15|              14.0|Unit 9800 Box 287...|Zuniga, Clark and...|                  1|\n",
            "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9cAofTKATxK",
        "outputId": "12f33b11-44c8-494c-8e10-2c401bd043bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|Churn|count|\n",
            "+-----+-----+\n",
            "|    1|  150|\n",
            "|    0|  750|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupBy('Churn').count().show() # Un problema imbalanceado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qfpqDwjuSPt"
      },
      "source": [
        "3.3. Obtenga el conjunto de datos con el vector de variables independientes y la variable dependiente (churn). Por simplicidad, es suficiente que seleccione únicamente las variables numéricas. Muestre los primeros 5 elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I71vzo75D0j",
        "outputId": "89a13136-3ef4-478a-a99a-066d755a2685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+\n",
            "|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|\n",
            "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+\n",
            "|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|\n",
            "|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|\n",
            "|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|\n",
            "|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|\n",
            "|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|\n",
            "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----+\n",
            "|Churn|\n",
            "+-----+\n",
            "|    1|\n",
            "|    1|\n",
            "|    1|\n",
            "|    1|\n",
            "|    1|\n",
            "+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x = df.select([c for c in df.columns if c != 'Churn']) # Para coger todas las columnas\n",
        "y = df.select([c for c in df.columns if c == 'Churn'])\n",
        "x.show(5)\n",
        "y.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP26gLcK5fHa",
        "outputId": "b01ca653-c774-45af-e0ad-7c9fc9f418f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+--------------+---------------+-----+---------+\n",
            "| Age|Total_Purchase|Account_Manager|Years|Num_Sites|\n",
            "+----+--------------+---------------+-----+---------+\n",
            "|42.0|       11066.8|              0| 7.22|      8.0|\n",
            "|41.0|      11916.22|              0|  6.5|     11.0|\n",
            "|38.0|      12884.75|              0| 6.67|     12.0|\n",
            "|42.0|       8010.76|              0| 6.71|     10.0|\n",
            "|37.0|       9191.58|              0| 5.56|      9.0|\n",
            "+----+--------------+---------------+-----+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "col_numericas = [c for c in x.columns if isinstance(x.schema[c].dataType, (IntegerType, DoubleType))] # Para seleccionar solo las numéricas\n",
        "\n",
        "df_dep_num = x.select([F.col(col_name) for col_name in col_numericas])\n",
        "df_dep_num.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "vwaCJtSg8VtP"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import *\n",
        "vectorAssembler = VectorAssembler(inputCols = df_dep_num.columns, outputCol = \"indep_vector\") # Vector de pyspark ML con todas las features independientes numéricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCZV4UK5uSPu"
      },
      "source": [
        "3.4. Realicé la separación en los conjuntos de entrenamiento y prueba con una proporción 70-30. Muestre los primeros 5 elementos de cada conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Pz8lnoT56DZC"
      },
      "outputs": [],
      "source": [
        "df_train, df_test = df.randomSplit([0.7, 0.3], seed=123)\n",
        "\n",
        "df_train = df_train.cache() # Las dejo en caché para mejorar la velocidad\n",
        "df_test = df_test.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lla9b9qYuSPu"
      },
      "source": [
        "3.5. Ajuste un modelo de regresión logística con los hiperparámetros por defecto. Muestre los estadísticos descriptivos de las predicciones contenidas en el resumen del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "q74BujdpEZba"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "LogisticRegression = LogisticRegression(labelCol=\"Churn\", featuresCol=\"indep_vector\") # Utilizando Pyspark ML, que está más enfocado en el uso de dataframes que MLlib\n",
        "\n",
        "pipeline = Pipeline(stages=[vectorAssembler, LogisticRegression])\n",
        "\n",
        "model = pipeline.fit(df_train)\n",
        "preds = model.transform(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgyMYSMA-mOK",
        "outputId": "54275b22-1e2e-41cb-e2c7-0df8c7033bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------+-------------------+\n",
            "|summary|         prediction|              Churn|\n",
            "+-------+-------------------+-------------------+\n",
            "|  count|                290|                290|\n",
            "|   mean|0.12758620689655173|0.15517241379310345|\n",
            "| stddev|0.33420519951075905| 0.3626948414649638|\n",
            "|    min|                0.0|                  0|\n",
            "|    max|                1.0|                  1|\n",
            "+-------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds.describe([\"prediction\", \"Churn\", \"probability\"]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y93ZcyiPuSPu"
      },
      "source": [
        "3.6. Evalúe los resultados en el conjunto de prueba. Muestre las primeras 5 predicciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEPjvOjH_ln3",
        "outputId": "d879b45f-fd78-472b-c758-89337afd89d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9172413793103448"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "eval = MulticlassClassificationEvaluator(labelCol=\"Churn\")\n",
        "acc = eval.evaluate(preds, {eval.metricName: \"accuracy\"})\n",
        "acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYRdX5sJuSPv"
      },
      "source": [
        "3.7. Para evaluar el desempeño del modelo, obtenga el valor del indicador auROC (área debajo de la curva ROC)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTtREvG6_SNx",
        "outputId": "4d1b5339-2fe9-4176-e694-3fbebb0df1a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9248979591836719"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "eval = BinaryClassificationEvaluator(labelCol=\"Churn\")\n",
        "auROC = eval.evaluate(preds, {eval.metricName: \"areaUnderROC\"})\n",
        "auROC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wNHC496uSPv"
      },
      "source": [
        "3.8. Cargue los datos del archivo 'data_new.csv' y obtenga las predicciones sobre ese conjunto de datos utilizando los objetos construidos previamente. Muestre los primeros 5 elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLmUQOoOCrbD",
        "outputId": "c77b82bd-298a-42ff-ffa9-1b94deafce91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|        indep_vector|       rawPrediction|         probability|prediction|\n",
            "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|[42.0,11066.8,0.0...|[2.56889492156846...|[0.92883268204289...|       0.0|\n",
            "|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|[41.0,11916.22,0....|[-0.5968316870018...|[0.35506888791642...|       1.0|\n",
            "|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|[38.0,12884.75,0....|[-1.7662401631392...|[0.14601052475887...|       1.0|\n",
            "|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|    1|[42.0,8010.76,0.0...|[0.65018795361486...|[0.65705281634105...|       0.0|\n",
            "|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|    1|[37.0,9191.58,0.0...|[2.68195435874064...|[0.93595337681535...|       0.0|\n",
            "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_new = spark.read.csv(\"data.csv\", header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "preds_new = model.transform(df_new)\n",
        "preds_new.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "She3La7fuSPv"
      },
      "source": [
        "# Fin de la evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDwsrobNvEXk"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
